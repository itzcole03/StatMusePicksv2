name: Alembic migration smoke test

on:
  pull_request:
    paths:
      - 'backend/**'
      - '.github/workflows/**'

jobs:
  alembic-smoke:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: statmuse_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres" --health-interval=5s --health-timeout=5s --health-retries=10

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
          pip install psycopg2-binary alembic

      - name: Wait for Postgres
        env:
          DATABASE_URL: "postgresql://postgres:postgres@localhost:5432/statmuse_test"
        run: |
          python - <<'PY'
import os, sys, time
import psycopg2
url = os.environ['DATABASE_URL']
for i in range(20):
    try:
        conn = psycopg2.connect(url)
        conn.close()
        print('Postgres reachable')
        sys.exit(0)
    except Exception as e:
        print('Waiting for Postgres...', e)
        time.sleep(2)
print('Postgres did not become ready', file=sys.stderr)
sys.exit(1)
PY

      - name: Run Alembic migrations
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/statmuse_test
        run: |
          pushd backend
          alembic upgrade head
          popd

      - name: Run smoke DB check
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/statmuse_test
        run: |
          python - <<'PY'
import os
from sqlalchemy import create_engine, text
url = os.environ['DATABASE_URL']
engine = create_engine(url)
with engine.connect() as conn:
    # Check a known table from migrations exists (model_metadata or player_stats)
    res = conn.execute(text("SELECT to_regclass('public.model_metadata')"))
    val = res.scalar()
    print('model_metadata exists?', bool(val))
    if not val:
        # As a fallback, list tables
        res = conn.execute(text("SELECT table_name FROM information_schema.tables WHERE table_schema='public' LIMIT 5"))
        print('Public tables (sample):', [r[0] for r in res.fetchall()])
        # Do not fail here if migrations intentionally don't create model_metadata in this branch
    print('DB smoke check complete')
PY
