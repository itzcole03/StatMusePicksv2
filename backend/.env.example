### Example environment variables for the backend
# If you run Redis locally, set REDIS_URL accordingly
REDIS_URL=redis://localhost:6379/0
# Database connection used by Alembic and the app. Defaults to sqlite for dev.
# Examples:
# Postgres: postgresql+asyncpg://user:pass@localhost:5432/statmuse_predictions
# SQLite (dev): sqlite+aiosqlite:///./dev.db
DATABASE_URL=sqlite+aiosqlite:///./dev.db

# Postgres example (for docker compose dev stack):
# postgresql+asyncpg://postgres:postgres@localhost:5432/statmuse_dev

# REDIS_URL example (if using docker-compose.dev.yml):
# REDIS_URL=redis://localhost:6379/0

# Ollama / embeddings configuration
# Set to your Ollama server or the Cloud API
# OLLAMA_URL=https://api.ollama.com
# OLLAMA_CLOUD_API_KEY=
# Default model to use for embeddings/generation
# OLLAMA_DEFAULT_MODEL=embedding-model-name
# In production set this to 'false' to disable deterministic fallback embeddings
# and fail when live embeddings are unavailable. In dev you can leave it unset
# to allow deterministic fallback for offline testing.
# OLLAMA_EMBEDDINGS_FALLBACK=false

# Vector store configuration
# Supported values: 'memory' (dev) or 'chroma'
# VECTOR_STORE=memory
# VECTOR_STORE=chroma
# When using Chroma:
# CHROMA_PERSIST_DIR=./chroma_data
# CHROMA_COLLECTION_NAME=statmuse

# Optional: allow the backend to attempt an `ollama pull <model>` when a model is missing.
# Not recommended for production unless you understand the implications.
# OLLAMA_ALLOW_AUTO_PULL=false
